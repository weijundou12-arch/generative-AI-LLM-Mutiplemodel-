Week14 面试冲刺总目标

你在面试里要做到三件事：

讲清楚你做了什么（What）：一个端到端系统，不是“我学了什么”。

讲清楚你为什么这么做（Why）：关键 trade-off（成本/质量/延迟/安全）。

讲清楚你怎么证明它有效（Evidence）：指标、消融、线上监控、故障处理。

Part A：你的“全栈项目”叙事模板（直接可套）

你就用一个主项目贯穿：
“可信医疗/金融研究助理：RAG + Agent + MCP 工具 + VLM + 微调对齐 + 分布式训练 + 推理加速服务化”

1）30 秒电梯陈述（必背）

满分回答：
我做了一个端到端的可信研究助理系统：底层是可微调的指令模型，上层用 RAG 做证据检索与引用溯源，用 Agent/MCP 调度工具（检索、计算、结构化抽取、审计），并扩展了多模态输入（图像报告/截图）。
训练侧我用 LoRA/QLoRA 做轻量微调，并用偏好对齐（DPO/PPO/GRPO）减少幻觉与提升格式遵循。
部署侧我做了 FastAPI 服务、鉴权与日志审计，并用连续批处理与分页 KV（PagedAttention 思路）提升吞吐，同时监控 prefill/decode 延迟与 KV cache 显存。
整体目标是：在质量可控前提下，降低延迟和成本，并能解释输出来源。

记住：你说的是“系统 + 证据 + 指标”，不是“我学了很多概念”。

2）2 分钟项目深挖结构（面试官追问就用）

按这个顺序说（像讲架构图）：

(1) 问题定义

用户要：可追溯的结论（引用证据），结构化输出（可进数据库），安全合规（不能乱编/泄露）。

难点：模型先验强，会补全缺失；文档来源复杂；请求并发与长上下文导致推理成本爆炸。

(2) 解决方案（分层）

数据层：文档切分、去噪、元数据（来源、时间、章节、置信度）。

检索层（RAG）：BM25+向量混合、重排；输出必须带引用。

智能体层（Agent/MCP）：把任务拆为检索→核验→计算→结构化输出→审计。

模型层：SFT 固化格式/拒答策略；DPO/PPO 对齐偏好（少幻觉）。

服务层：FastAPI + 鉴权 + 限流 + 审计；观测 prefill/decode。

性能层：连续批处理、KV 管理、量化/蒸馏策略。

(3) 结果与指标（必须说出数字/指标口径）

结构化输出解析成功率：例如 JSON parse rate

幻觉率：无证据陈述比例

延迟：prefill ms / decode ms，p95

成本：tokens/s、GPU 利用率、每 1k tokens 成本

3）STAR 模板（你讲任何项目都可用）

S（Situation）：为什么要做？什么约束？

T（Task）：你负责什么？指标是什么？

A（Action）：你怎么设计、怎么取舍、怎么实现？

R（Result）：指标变化、对比实验、线上收益。

Part B：高频追问（每题“满分简答”）

下面这些是面试官最常把你打穿的点。我给你“短但满分”的答法。

1）“为什么不用纯 RAG？为什么还要微调？”

满分回答：
RAG 解决“知识获取与可追溯”，但不稳定：格式、拒答、工具调用习惯很难只靠 prompt 固化；微调能把行为写进权重，提升一致性与执行力。我的实践是：RAG 提供证据，微调学会“如何用证据回答并在不足时拒答”。

2）“你怎么降低幻觉？”

满分回答：
我用三层：

检索层：强制引用与重排，减少错误上下文；

训练层：加入“证据不足→拒答”的负样本，并用 DPO/RLHF 强化这种偏好；

评测层：统计无证据陈述比例，线上监控失败样例回流再训练。

3）“embedding 检索为什么不够？为什么要 rerank？”

满分回答：
向量检索召回强但排序不一定符合问句细粒度需求；rerank 用 cross-encoder 重新打分能显著提高 top-k 精度，减少模型读到错误 chunk 造成幻觉。成本更高，所以只对小候选集 rerank。

4）“chunk 怎么切？切太小/太大有什么后果？”

满分回答：
切太小：语义断裂、引用不完整；切太大：噪声多、检索不准、上下文成本高。我的做法是：按结构（标题/段落）切，设置 overlap，并把来源、章节号作为元数据，保证引用可定位。

5）“DPO 和 PPO 你怎么选？”

满分回答：
DPO 工程简单稳定、成本低，适合偏好对齐的第一选择；PPO 更灵活，适合复杂奖励或在线交互，但更难训且成本高。我一般先 DPO 做基线，再决定是否上 PPO。

6）“GRPO/RLVR 为什么适合推理任务？”

满分回答：
当 reward 可验证（数学、代码测试、JSON schema），可以用组内相对优势替代 critic，省掉 value 模型训练，同时用验证器做奖励更可靠，推理能力提升更直接。

7）“ZeRO-2/3 你怎么选？”

满分回答：
先 ZeRO-2：显存收益大、通信成本可控；装不下再上 ZeRO-3；再不行才 offload。因为 ZeRO-3 参数分片会引入更频繁的 all-gather，吞吐更敏感。

8）“推理为什么慢？你怎么优化？”

满分回答：
decode 阶段 memory-bound，KV cache 随长度和并发线性增长。优化顺序：连续批处理提升利用率 → 分页 KV 管理减少碎片 → 量化降低带宽/显存 → 必要时 speculative decoding 减少大模型步数。监控上拆 prefill/decode 指标。

9）“如何证明系统有效，不是‘感觉变好了’？”

满分回答：
做可复现评测：固定测试集、固定提示，比较：

引用命中率、幻觉率（无证据陈述）

JSON 解析成功率

p95 延迟、tokens/s、成本
并做消融（去 rerank / 去微调 / 去拒答样本），定位贡献。

10）“如果检索到了错误证据怎么办？”

满分回答：

retriever+rerank 提升准确性；

让模型输出“证据-结论对齐”，必要时给出不确定性；

对高风险问题加二次核验工具（比如数值一致性检查/规则校验）；

线上把错误 case 回流，更新索引与训练数据。

Part C：Mock 面试题库（3 套：工程/系统/研究）
Mock 1（偏工程落地）

用 2 分钟讲你的 RAG+Agent 系统，列出 3 个关键 trade-off。

解释 rerank 的必要性与成本控制。

你怎么做日志审计与权限控制？

线上 p95 延迟突然升高，你排查顺序是什么？

你如何让输出稳定为 JSON？怎么评测？

你答题要点：“分层 → 指标 → 排障路径”。

Mock 2（偏系统与性能）

decode 为何更慢？KV cache 如何估算？

PagedAttention 为什么能提高吞吐？

ZeRO-2 vs ZeRO-3 通信差异？

什么情况下用 TP/PP？

你会如何做容量规划（并发/上下文/显存）？

你答题要点：“瓶颈分析 + 公式 + 选型逻辑”。

Mock 3（偏研究与训练）

SFT 数据怎么设计才能减少幻觉？

DPO 的目标函数直觉是什么？β 做什么？

RLVR 怎么构建 reward？如何避免 reward hacking？

你如何做消融实验？

多模态对齐在对齐什么？为什么会看图胡说？

你答题要点：“why + 实验设计”。

Part D：面试用“项目材料包”（你要准备的 5 件东西）

你只要准备这些，就能把 Week1–13 全串起来：

一张架构图（RAG → Agent/MCP → Model → Serve → Monitor）

一页指标表（质量/延迟/成本/可靠性）

一个 demo 视频（30–60 秒：从请求到引用到 JSON 输出）

一个故障复盘（例如：检索错误导致幻觉、如何修）

一个技术深挖点（任选：ZeRO-3 或 Paged KV 或 DPO）

Part E：你可以直接背的“10 句金句”（很提气但不空）

“我把问题拆成：知识获取（RAG）与行为固化（SFT/对齐）两层。”

“我用引用溯源把输出变成可审计的证据链。”

“我把推理分成 prefill/decode 两段看瓶颈。”

“KV cache 是长上下文并发推理的第一显存杀手。”

“连续批处理保证 GPU 饱和，分页 KV 管理减少碎片。”

“DPO 是我偏好对齐的默认起点，PPO 用在复杂奖励。”

“ZeRO-2 先跑通，装不下再 ZeRO-3，最后才 offload。”

“我用负样本训练拒答，靠评测闭环降低幻觉。”

“我用消融实验定位每个组件对指标的贡献。”

“上线优先保证质量与可回滚，然后逐步做性能优化。”
