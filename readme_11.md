Week11 面试考点（满分简答版）
1）面试考点：什么是多模态大模型（VLM）？和纯文本 LLM 本质区别？

满分简答：
多模态模型能同时处理图像/文本（甚至视频/音频），把视觉输入编码为“可与文本 token 交互的表示”，再生成文本或结构化输出。本质区别在于：LLM 只在文本 token 空间建模；VLM 需要解决“视觉→token 化/对齐→与语言模型融合”的问题，否则语言模型无法把图像当作可推理的上下文。

**为什么重要：**企业/医疗/工业场景很多信息只存在于图像里（检查图、截图、表格、设备照片），单纯 RAG 只能管文本，VLM 才能把“视觉证据”纳入推理链路。

2）面试考点：VLM 的典型架构有哪些？优缺点是什么？

满分简答：
常见三类（你要能一口气说清）：

双塔 + 融合（Two-Tower + Fusion）：视觉编码器（ViT/ConvNeXt）+ 语言模型（LLM），通过 cross-attention 或中间层融合。

优点：可控、模块化强；

缺点：实现复杂、算力更大。

视觉编码器 + Projector + LLM（最常见）：图像→视觉特征→投影到 LLM 隐空间→当作“视觉 token”拼到 prompt 里（LLaVA/Qwen2-VL 这类）。

优点：工程最主流，微调成本低；

缺点：视觉能力上限受 projector 与视觉塔影响，且容易对“细粒度 OCR/小字”敏感。

统一自回归（Unified Autoregressive）：图像也离散化成 token（VQ/dVAE/Tokenizer），统一序列建模。

优点：形式统一；

缺点：训练成本高、工程生态少。

**为什么：**面试官在考你是否理解“图像如何进入 LLM 的 token 世界”，以及你能否根据资源/任务选择架构。

3）面试考点：Projector（视觉适配器）是干嘛的？为什么它是微调首选？

满分简答：
Projector 把视觉编码器输出（比如每个 patch 的向量）映射到 LLM 的隐藏维度，使得 LLM 能把这些向量当“前置上下文 token”来 attend。
微调时优先调 Projector/LoRA，是因为：改变少量参数就能显著改善对齐与指令跟随，成本低、稳定，且避免破坏基座语言能力（灾难性遗忘更小）。

4）面试考点：多模态“对齐（alignment）”到底在对齐什么？

满分简答：
对齐的是：“同一语义在视觉与语言空间能互相定位”。比如图中“ACL 撕裂箭头所指区域”应在语言输出中稳定对应。对齐通常靠大规模图文对（caption/alt-text）、VQA、OCR、指令数据完成：让模型学会把图像信息转成可表达、可执行的语言结论。

5）面试考点：为什么 VLM 很容易“看图胡说”？怎么降幻觉？

满分简答：
原因：视觉输入噪声大、分辨率/裁剪导致信息缺失、训练数据偏差、语言模型强先验会补全缺失细节。
工程手段：

高分辨率/多裁剪（减少信息缺失）

“证据约束输出”（要求指出依据区域/引用 OCR 结果）

拒答策略（看不清/无证据→明确说不确定）

用可验证任务做 RLVR（例如：表格数字必须与 OCR 一致、JSON schema 必须通过）

6）面试考点：多模态数据怎么做（指令微调）？格式最关键是什么？

满分简答：
关键是把样本拆成：image(s) + messages（system/user/assistant），并保证训练与推理 template 一致。
高质量多模态指令数据应包含：

图像描述（caption）

视觉问答（VQA）

OCR/表格抽取

结构化输出（JSON）

**“看不清/证据不足→拒答”**负样本（非常加分）

7）面试考点：多模态微调怎么选：全参 / LoRA / QLoRA？

满分简答：

LoRA：工业默认，训练快、成本低；通常对 LLM 的 attention/MLP 加 LoRA，有时也对 projector 加 LoRA/解冻 projector。

QLoRA：显存不足时把基座 4bit 加载，仅训 LoRA；代价是吞吐可能下降且更敏感。

全参：只在数据极大、资源充足、要显著改模型能力时考虑，否则风险高（遗忘、对齐漂移）。

8）面试考点：多模态评测怎么做才算“研究/工程合格”？

满分简答：
分三层：

任务指标：VQA accuracy、OCR exact match、结构化输出解析成功率

可靠性：拒答正确率、幻觉率（无图信息的错误陈述比例）

线上指标：延迟、吞吐、失败率、热力图/引用证据可解释性

9）面试考点：多模态部署的关键瓶颈是什么？怎么优化？

满分简答：
瓶颈通常在视觉编码（高分辨率 ViT）与 KV cache 占用。优化：

低分辨率与多裁剪折中、批处理

视觉塔缓存（同图多问复用视觉特征）

量化（LLM 部分）+ 合理 max_tokens

服务端做 request batching、超时与降级（必要时返回“无法确认”）

10）面试考点（医疗/隐私加分）：医学影像多模态要注意什么？

满分简答：
PHI/隐私（DICOM 信息、面部、姓名）、训练数据合规、以及“临床安全”：模型输出必须带不确定性与建议（需要医生确认），并避免给出超出证据的诊断承诺。
